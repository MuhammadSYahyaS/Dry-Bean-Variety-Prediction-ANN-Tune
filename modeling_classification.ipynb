{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dry Bean Variety Prediction by Multiclass Classification using ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset for the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train: 9528\n",
      "Num val: 1361\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1885</td>\n",
       "      <td>45130</td>\n",
       "      <td>793.896</td>\n",
       "      <td>300.179289</td>\n",
       "      <td>191.903596</td>\n",
       "      <td>1.564219</td>\n",
       "      <td>0.768960</td>\n",
       "      <td>45635</td>\n",
       "      <td>239.710869</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.988934</td>\n",
       "      <td>0.899804</td>\n",
       "      <td>0.798559</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.637696</td>\n",
       "      <td>0.997497</td>\n",
       "      <td>SIRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6754</td>\n",
       "      <td>55559</td>\n",
       "      <td>934.184</td>\n",
       "      <td>369.299024</td>\n",
       "      <td>192.668844</td>\n",
       "      <td>1.916755</td>\n",
       "      <td>0.853120</td>\n",
       "      <td>56331</td>\n",
       "      <td>265.969765</td>\n",
       "      <td>0.652009</td>\n",
       "      <td>0.986295</td>\n",
       "      <td>0.800017</td>\n",
       "      <td>0.720202</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.518690</td>\n",
       "      <td>0.994203</td>\n",
       "      <td>HOROZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8383</td>\n",
       "      <td>83982</td>\n",
       "      <td>1174.925</td>\n",
       "      <td>412.055694</td>\n",
       "      <td>260.285953</td>\n",
       "      <td>1.583088</td>\n",
       "      <td>0.775232</td>\n",
       "      <td>85570</td>\n",
       "      <td>327.000311</td>\n",
       "      <td>0.741956</td>\n",
       "      <td>0.981442</td>\n",
       "      <td>0.764497</td>\n",
       "      <td>0.793583</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.629774</td>\n",
       "      <td>0.996987</td>\n",
       "      <td>BARBUNYA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9464</td>\n",
       "      <td>33213</td>\n",
       "      <td>684.270</td>\n",
       "      <td>261.487558</td>\n",
       "      <td>162.196575</td>\n",
       "      <td>1.612164</td>\n",
       "      <td>0.784377</td>\n",
       "      <td>33610</td>\n",
       "      <td>205.640718</td>\n",
       "      <td>0.727637</td>\n",
       "      <td>0.988188</td>\n",
       "      <td>0.891380</td>\n",
       "      <td>0.786426</td>\n",
       "      <td>0.007873</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.618466</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6555</td>\n",
       "      <td>48856</td>\n",
       "      <td>831.807</td>\n",
       "      <td>314.074497</td>\n",
       "      <td>198.512622</td>\n",
       "      <td>1.582139</td>\n",
       "      <td>0.774923</td>\n",
       "      <td>49420</td>\n",
       "      <td>249.410086</td>\n",
       "      <td>0.712810</td>\n",
       "      <td>0.988588</td>\n",
       "      <td>0.887325</td>\n",
       "      <td>0.794111</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.630613</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>SIRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Area  Perimeter  MajorAxisLength  MinorAxisLength  \\\n",
       "0        1885  45130    793.896       300.179289       191.903596   \n",
       "1        6754  55559    934.184       369.299024       192.668844   \n",
       "2        8383  83982   1174.925       412.055694       260.285953   \n",
       "3        9464  33213    684.270       261.487558       162.196575   \n",
       "4        6555  48856    831.807       314.074497       198.512622   \n",
       "\n",
       "   AspectRation  Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  \\\n",
       "0      1.564219      0.768960       45635     239.710869  0.794095  0.988934   \n",
       "1      1.916755      0.853120       56331     265.969765  0.652009  0.986295   \n",
       "2      1.583088      0.775232       85570     327.000311  0.741956  0.981442   \n",
       "3      1.612164      0.784377       33610     205.640718  0.727637  0.988188   \n",
       "4      1.582139      0.774923       49420     249.410086  0.712810  0.988588   \n",
       "\n",
       "   roundness  Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  \\\n",
       "0   0.899804     0.798559      0.006651      0.001668      0.637696   \n",
       "1   0.800017     0.720202      0.006647      0.001103      0.518690   \n",
       "2   0.764497     0.793583      0.004906      0.001200      0.629774   \n",
       "3   0.891380     0.786426      0.007873      0.001858      0.618466   \n",
       "4   0.887325     0.794111      0.006429      0.001577      0.630613   \n",
       "\n",
       "   ShapeFactor4     Class  \n",
       "0      0.997497      SIRA  \n",
       "1      0.994203     HOROZ  \n",
       "2      0.996987  BARBUNYA  \n",
       "3      0.997070  DERMASON  \n",
       "4      0.997717      SIRA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(os.path.join(\"DryBeanDataset\", \"dry_bean_train.csv\"))\n",
    "df_val = pd.read_csv(os.path.join(\"DryBeanDataset\", \"dry_bean_val.csv\"))\n",
    "print(\"Num train:\", len(df_train))\n",
    "print(\"Num val:\", len(df_val))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset loader for training and validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features to be used and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = [\"Area\", \"Perimeter\", \"MajorAxisLength\", \"MinorAxisLength\", \"Eccentricity\", \"ConvexArea\", \"EquivDiameter\", \"Extent\", \"Solidity\", \"ShapeFactor1\", \"ShapeFactor2\", \"ShapeFactor3\", \"ShapeFactor4\"]\n",
    "y_name = \"Class\"\n",
    "y_classes = [\"SEKER\", \"BARBUNYA\", \"BOMBAY\", \"CALI\", \"DERMASON\", \"HOROZ\", \"SIRA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Pandas dataframe to PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(df: pd.DataFrame) -> Dataset:\n",
    "    features = df[x_names].to_numpy(dtype=np.float32)\n",
    "    # preprocess data\n",
    "    df[\"Area\"] /= 500_000\n",
    "    df[\"Perimeter\"] /= 5000\n",
    "    df[\"MajorAxisLength\"] /= 2000\n",
    "    df[\"MinorAxisLength\"] /= 2000\n",
    "    df[\"ConvexArea\"] /= 500_000\n",
    "    df[\"EquivDiameter\"] /= 2000\n",
    "    # preprocess labels\n",
    "    labels = df[[y_name]].applymap(lambda x: y_classes.index(x)) # map Class labels to int\n",
    "    labels = labels.to_numpy(dtype=np.int64).squeeze(axis=1)\n",
    "    # create the dataset\n",
    "    features = torch.from_numpy(features)\n",
    "    labels = torch.from_numpy(labels)\n",
    "    my_dataset = TensorDataset(features, labels)\n",
    "    return my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = df_to_dataset(df_train)\n",
    "ds_val = df_to_dataset(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PyTorch data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "loader_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True) # drop last for stability\n",
    "loader_val = DataLoader(ds_val, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 1000\n",
    "INIT_LR = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which device we will use for training process (CPU/GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.MLP4Layers(n_features=len(x_names), n_classes=len(y_classes))\n",
    "# Move the model from CPU to the device\n",
    "# Actually, only required if the device is not CPU and has no effect if it is CPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=INIT_LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, min_lr=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model weights and logs to: runs_clf/train_20220904_081814\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_dir = os.path.join('runs_clf', 'train_{}'.format(timestamp))\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "writer = SummaryWriter(save_dir)\n",
    "print(f\"Saving model weights and logs to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training and validation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training process, launch tensorboard to see the logged train/val metrics\n",
    "```bash\n",
    "tensorboard --logdir runs_clf\n",
    "```\n",
    "Then, open the link using web browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d6ad7826a24695a3a0c1b06dc6f9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variables to hold some training status\n",
    "epoch_number = 0\n",
    "lowest_loss = np.inf\n",
    "best_f1 = 0.\n",
    "# Training loop\n",
    "for epoch in tqdm(range(MAX_EPOCHS)):\n",
    "    # Make sure gradient tracking is on, and do a pass over the data for the training process\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    for i, data in enumerate(loader_train):\n",
    "        # Every data instance is an input & label pair\n",
    "        inputs, labels = data\n",
    "        # We move the data instance from CPU to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        # Gather data and report\n",
    "        running_loss += loss.detach().item()\n",
    "    # Calculate the average training loss\n",
    "    avg_loss = running_loss / (i + 1)\n",
    "\n",
    "    # We don't need gradients for the model validation process\n",
    "    model.eval()\n",
    "    running_vloss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(loader_val):\n",
    "            vinputs, vlabels = vdata\n",
    "            y_true.extend(vlabels.numpy().tolist())\n",
    "            voutputs = model(vinputs.to(device))\n",
    "            vloss = loss_fn(voutputs, vlabels.to(device))\n",
    "            running_vloss += vloss.item()\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(voutputs.data, 1)\n",
    "            y_pred.extend(predicted.cpu().numpy().tolist())\n",
    "\n",
    "    # Calculate the average validation loss\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    scheduler.step(avg_vloss)\n",
    "    # Calculate our classification metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalar('train/loss', avg_loss, epoch_number + 1)\n",
    "    writer.add_scalar('val/loss', avg_vloss, epoch_number + 1)\n",
    "    writer.add_scalar('val/acc', acc, epoch_number + 1)\n",
    "    writer.add_scalar('val/weighted_f1', f1, epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "\n",
    "    # Track best performance, and save the model's state (weights)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        model_path = os.path.join(save_dir, 'best.pt')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    if avg_vloss < lowest_loss:\n",
    "        lowest_loss = avg_vloss\n",
    "        model_path = os.path.join(save_dir, 'lowest_loss.pt')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    model_path = os.path.join(save_dir, 'last.pt')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] https://pytorch.org/tutorials/beginner/introyt/trainingyt.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ai_class')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45806f2a31fc2394908bf2aae38bc8f96498b1e9c39d8308e884e6256764b6c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
